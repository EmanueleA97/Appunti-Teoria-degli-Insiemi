\documentclass[11pt]{scrartcl}
\usepackage[italian]{babel}
\usepackage[sexy]{evan} %evan.sty

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% BOOST SOFTWARE LICENSE - VERSION 1.0 - 17 AUGUST 2003
%
% Copyright (c) 2022 Evan Chen [evan at evanchen.cc]
% https://web.evanchen.cc/ || github.com/vEnhance
%
% Available for download at:
% https://github.com/vEnhance/dotfiles/blob/main/texmf/tex/latex/evan/evan.sty
%
% Permission is hereby granted, free of charge, to any person or organization
% obtaining a copy of the software and accompanying documentation covered by
% this license (the "Software") to use, reproduce, display, distribute,
% execute, and transmit the Software, and to prepare derivative works of the
% Software, and to permit third-parties to whom the Software is furnished to
% do so, all subject to the following:
%
% The copyright notices in the Software and this entire statement, including
% the above license grant, this restriction and the following disclaimer,
% must be included in all copies of the Software, in whole or in part, and
% all derivative works of the Software, unless such copies or derivative
% works are solely in the form of machine-executable object code generated by
% a source language processor.
%
% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
% FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
% SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
% FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
% ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
% DEALINGS IN THE SOFTWARE.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\title{Elementi Di Teoria Degli Insiemi}
\subtitle{\large\normalfont\rmfamily\scshape APPUNTI DEL CORSO DI ELEMENTI DI TEORIA DEGLI INSIEMI \\ TENUTO DAL PROF. MARCELLO MAMINO}
\author{Diego Monaco \\ \textnormal{\href{d.monaco2@studenti.unipi.it}{d.monaco2@studenti.unipi.it}} \\ Università di Pisa}
\date{Anno Accademico 2022-23}
\maketitle
\newpage

\tableofcontents
\eject
\newpage

\section*{Premessa}
Queste dispense sono la quasi esatta trascrizione in \LaTeX\,delle dispense del corso di Elementi di teoria degli insiemi, tenuto dal prof. Marcello Mamino nell'anno accademico 2022-23.

\section*{Ringraziamenti}
Francesco Sorce.

\mbox{}
\vfill
\begin{wrapfigure}{R}{0.2\textwidth}
	\centering
	\href{https://creativecommons.org/licenses/by-nc/4.0/deed.it}{\includegraphics[width=0.2\textwidth]{licenza.png}}
\end{wrapfigure}

Quest'opera è stata rilasciata con licenza Creative Commons Attribuzione - Condividi allo stesso modo 4.0 Internazionale. Per leggere
una copia della licenza visita il sito web \href{http://creativecommons.org/licenses/by-sa/4.0/deed.it}{\textcolor{blue}{https://creativecommons.org/licenses/by-nc/4.0/deed.it}}.\\

\newpage

\newpage
\section{Prologo nel XIX secolo}
La nascita della teoria degli insiemi è una storia complicata di cui so pochissimo. Però, persone che ne sanno molto più di me hanno sostenuto l'opinione che il problema seguente
abbia avuto un ruolo. Come che sia, è almeno un'introduzione possibile.

\begin{problem}
Data una serie trigonometrica:
\[ S(x) = c_0 + \sum_{i=1}^{+\infty}a_i\sin{(ix)}+b_i\cos{(ix)}
	\]
se, per ogni $x \in \RR$, sappiamo che $S(x)$ converge a 0, possiamo dire che i coefficienti $c_0,a_i,b_i$ sono tutti 0?
\end{problem}

Risolto positivamente da \href{https://it.wikipedia.org/wiki/Georg_Cantor}{\textcolor{purple}{Georg Cantor}} nel 1870.

\begin{definition}
Diciamo che $X \subseteq \RR$ è un \vocab{insieme di unicità} se, per ogni serie trigonometrica:
\[ S(x) = c_0 + \sum_{i=1}^{+\infty}a_i\sin{(ix)}+b_i\cos{(ix)}
	\]
vale la seguente implicazione:
\[ \text{$S(x)$ converge a 0 per tutti gli $x\not\in X$} \implies \text{tutti i coefficienti $c_0,a_i,b_i$ sono nulli}
	\]
\end{definition}

\begin{example}
	Per il risultato di Cantor, $\emptyset$ è di unicità.
\end{example}

\begin{problem}
	Quali sottoinsiemi di $\RR$ sono di unicità?
\end{problem}

\begin{fact}
\label{unicità}
$X \subseteq \RR$ è di unicità se (ma non solo se) ogni funzione continua $f : \RR \longrightarrow \RR$ che soddisfi le ipotesi seguenti è necessariamente lineare\footnote{$f(x) = \alpha x + \beta$.}:
\begin{itemize}
	\item per ogni intervallo aperto $\left]a,b\right[$ con $]a,b[ \cap X = \emptyset$, $f_{|\left]a,b\right[}$ è lineare;
	\item per ogni $x \in \RR$, se $f$ ha derivate destre e sinistre in $x$, allora queste coincidono\footnote{Ovvero $f$ non ha punti angolosi.}.
\end{itemize}
\end{fact}

\begin{example}
	$X = \{\ldots,a_{-2},a_{-1},a_0,a_1,a_2,\ldots\} = \{a_i | i \in \ZZ\}$ con $\ldots < a_{-2} < a_{-1} < a_0 < a_1 < a_2 <\ldots$, $\displaystyle\lim_{i \to +\infty} a_i = +\infty$, $\displaystyle\lim_{i \to -\infty} a_i = -\infty$ ha la 
	proprietà data dal \hyperref[unicità]{Fatto 1.5}, quindi è di unicità.
\end{example}

\begin{notexample}
L'intervallo $[0,1]$ o $\RR$ non hanno la proprietà espressa dall'\hyperref[unicità]{Fatto 1.5}.
\end{notexample}

\begin{notexampleb}
Per l'\vocab{insieme di Cantor} non vale il \hyperref[unicità]{Fatto 1.5}.
\end{notexampleb}

Possiamo costruire l'insieme di Cantor a partire dall'intervallo $C_0 = [0,1]$ nel seguente modo:

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=12.5cm]{immagini/cantor.png}
	\end{figure}
\end{center}

ovvero, preso l'intervallo $[0,1]$ possiamo dividerlo in tre parti e rimuovere la parte centrale $\displaystyle\left]\frac 13, \frac 23\right[$, chiamiamo gli intervalli rimanenti $C_1$, possiamo iterare il procedimento sui due segmenti di $C_1$ ed ottenere $C_2,C_3,\ldots$, a questo punto 
definiamo l'insieme di Cantor $C$ come:
\[ C := \bigcap_{i \in \NN}C_i
	\]
Esiste una funzione continua (e crescente) $f : \RR \longrightarrow \RR$ detta \vocab{scala di Cantor} (o \vocab{scala del diavolo}), tale che $f^{\prime}(x) = 0$ per $x \not\in C$ e non è 
derivabile in $x \in C$.

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=13.5cm]{immagini/scalacantor.png}
	\end{figure}
\end{center}

tale funzione si costruisce aggiungendo tratti costanti (prima $\displaystyle\frac 12$, poi $\displaystyle\frac 14$, $\displaystyle\frac 34$ e così via, dividendo l'intervallo $[0,1]$ sull'asse delle ordinate in parti uguali) alle parti eliminate sull'intervallo
$[0,1]$ sull'asse delle ascisse per costruire l'insieme di Cantor.

\begin{note}
Per $\QQ$ e $C$ non vale il \hyperref[unicità]{Fatto 1.5} ma, in realtà, sono di unicità.
\end{note}

\begin{exampleb}
L'insieme degli elementi di una successione crescente col suo limite è un esempio di insieme di unicità.
\end{exampleb}

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=10.5cm]{immagini/succunic.png}
	\end{figure}
\end{center}

Dimostriamo quindi che $X$ è un insieme di unicità.
\begin{proof}
La funzione $f$ è lineare in $]-\infty, a_0[, ]a_0,a_1[, ]a_1,a_2[, \ldots$. Quindi nei punti $a_0,a_1,a_2,\ldots$ ammette derivata destra e sinistra. 
Siccome questi punti non possono essere angolosi, $f_{|]-\infty, a_0[}$, $f_{|]a_0,a_1[}$, etc. hanno lo stesso coefficiente angolare, quindi, sfruttando la cardinalità, $f_{|]-\infty, a_0[}$
è lineare. Siccome $f_{|]-\infty, a_0[}$ è lineare, usando nuovamente l'assenza di punti angolosi abbiamo la tesi.
\end{proof}

\begin{examplebb}
L'insieme degli elementi di una successione crescente di successioni crescenti è un insieme di unicità.
\end{examplebb}

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=12.5cm]{immagini/succunic2.png}
	\end{figure}
\end{center}

Dimostriamo che $X$ è di unicità.
\begin{proof}
In ciascuno degli intervalli $]a_{i0}, a_{(i+1)0}[$, $f$ è lineare, ragionando come nell'esempio precedente, ci siamo ridotti alla situazione
- di nuovo - dell'esempio precedente con $a_i^{\prime} = a_{i0}$.
\end{proof}

\subsection{Digressione: insiemi numerabili}
\begin{definition}
	Un insieme $X$ è \vocab{numerabile} se è il supporto di una successione, $X = \{a_0,a_1,a_2,\ldots\} = \{a_i | i \in \NN\}$, con $a_i \ne a_j$ per ogni $i \ne j$.\footnote{O in altre parole se esiste $f : \NN \longrightarrow X$ biunivoca.}
\end{definition}

\begin{example}
	Alcuni esempi di insiemi numerabili sono:
	\begin{itemize}
		\item $\NN$, l'insieme dei numeri naturali, infatti, la successione $a_i = i$ realizza la bigezione.
		\item I numeri dispari, con la bigezione data da $a_i = 2i + 1$.
		\item I numeri primi, $a_i = p_i$, con $p_i$ $i$-esimo numero primo.
		\item $\ZZ$ l'insieme dei numeri interi, con la bigezione data da $a_i = \displaystyle (-1)^i \left\lceil\frac{i}{2}\right\rceil$.
	\end{itemize}
\end{example}

\begin{examplem}
L'insieme $\NN \times \NN = \{(x,y) | x,y \in \NN\}$ è numerabile.
\end{examplem}

\begin{proof}
La funzione $f : \NN \times \NN \longrightarrow \NN : (x,y) \longmapsto 2^x(1+2y) - 1$ è biunivoca (perché?), quindi $a_i = f^{-1}(i)$ enumera $\NN \times \NN$.
\end{proof}

\begin{proposition}
Un sottoinsieme infinito di un insieme numerabile è, a sua volta, numerabile.
\end{proposition}

\begin{proof}
Sia $Y \subseteq X$ con $Y$ infinito e $X = \{a_i | i \in \NN\}$. La sottosuccessione $b_j = a_{i_j}$ degli $a_*$ che appartengono a $Y$ enumera $Y$. A essere precisi 
bisognerebbe dire esattamente chi sono gli indici $i_j$. Per ricorsione:
\[ i_0 = \min\{i | a_i \in Y\} \qquad i_{j+1} = \min\{i > i_j | a_i \in Y\}
	\]
dove i minimi esistono perché $Y$ non è finito.
\end{proof}

\begin{proposition}
Se $X$ e $Y$ sono numerabili $X \times Y = \{(a,b) | a \in X, b \in Y\}$ è anch'esso numerabile.
\end{proposition}

\begin{proof}
Fissiamo $X = \{a_i | i \in \NN\}$, $Y = \{b_j | j \in \NN\}$. Siccome $\NN \times \NN$ è numerabile, $\NN \times \NN = \{(i_t,j_t)|t \in \NN\}$.
Quindi $X \times Y = \{(a_{i_t}, a_{j_t}) | t \in \NN\}$.
\end{proof}

\begin{example}
$\QQ$ è numerabile.
\end{example}

\begin{proof}
$\QQ$ è in corrispondenza biunivoca con:
\[F = \{(\text{num.},\text{den.})\footnote{num. = numeratore, den. = denominatore.} | \text{num. $\in \ZZ$} \wedge \text{den. $\in\NN_{>0}$} \wedge \text{M.C.D.(num.,den.) = 1}\} \subseteq \ZZ \times \NN\]
\end{proof}

\begin{notexample}
$\RR$ non è numerabile.
\end{notexample}

\begin{proof}
Supponendo, per assurdo, che $\RR = \{a_i | i \in \NN\}$, cerchiamo un $x \in \RR$ che non compare fra gli $a_i$. Allo scopo, costruiamo la sottosuccessione $a_{i_j}$
definita per ricorrenza da:
\[ i_0 = 0 \qquad i_1 = \min\{i | a_i > a_0\} \qquad i_{j+1} = \min\{i | \, \text{$a_i$ è compreso tra $a_{j-1}$ e $a_j$}\}
	\]
graficamente:

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=10.5cm]{immagini/RRnum.png}
	\end{figure}
\end{center}

Si vede facilmente (esercizio!) che la successione $\{a_{i_{2k}}\}_k$ è crescente, $\{a_{i_{2k+1}}\}_k$ è decrescente 
e $\displaystyle \lim_{k \to +\infty} a_{i_{2k}} \leq \lim_{k \to +\infty}a_{i_{2k+1}}$. Fissiamo $x$ tale che $\displaystyle \lim_{k \to +\infty} a_{i_{2k}} \leq x \leq \lim_{k \to +\infty} a_{i_{2k+1}}$.
Chiaramente $x$ non è nessuno degli $a_{i_j}$, perché $a_{i_2k} < x < a_{i_{2k+1}}$. Supponiamo $x = a_n$, allora ci sarà $j$ tale che $i_j < n < i_{j+1}$, ma 
questo è assurdo perché allora $x = a_n$ è compreso fra $a_{i_{j-1}}$ e $a_{i_j}$, però $n < i_{j+1}$ contro la minimalità di quest'ultimo.

\begin{exercise}
Completare la dimostrazione nel caso $n < i$.
\end{exercise}

\begin{exercise}
Dimostrare che l'insieme di Cantor $C$ non è numerabile.
\end{exercise}
\end{proof}

\pagebreak
\subsection{Tornando agli insiemi di unicità}

\begin{theorem}
[Cantor-Lebesgue]
\label{CL}
Se $X \subseteq \RR$ è chiuso e numerabile, allora $X$ soddisfa il \hyperref[unicità]{Fatto 1.5}, ed è, quindi, di unicità.
\end{theorem}

La strategia di dimostrazione passa attraverso una definizione.

\begin{definition}
Dato $X \subseteq \RR$, il \vocab{derivato di Cantor-Bendixson} di $X$ è:
\[ X^{\prime} = X \setminus\{\text{punti isolati di $X$}\}
	\]
(dove $a \in X$ è un \vocab{punto di accumulazione} se $\exists \varepsilon > 0 : ]a - \varepsilon, a + \varepsilon[ \cap X = \{a\}$).
\end{definition}

\begin{remark}
Se $X$ è chiuso e per $X^{\prime}$ vale il \hyperref[unicità]{Fatto 1.5}, allora anche per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{remark}

Dimostriamo questo fatto.

\begin{proof}
Occorre dimostrare che se $f$ è continua, lineare, ristretta agli intervalli aperti che non intersecano $X$, e non ha punti angolosi, allora $f$ è
lineare ristretta agli intervalli aperti che non intersecano $X^{\prime}$. Fatto questo, usando l'ipotesi su $X^{\prime}$, $f$ è lineare - abbiamo quindi
mostrato che per $X$ vale \hyperref[unicità]{Fatto 1.5}.\\
Sia $]a,b[ \cap X^{\prime} = \emptyset$, dobbiamo dire che $f_{|]a,b[}$ è lineare. Ci basta dire che per ogni $\varepsilon > 0$, $f_{|[a+\varepsilon, b-\varepsilon]}$ è lineare.
Siccome $]a,b[ \cap X^{\prime} = \emptyset$, $]a,b[ \cap X = \{\text{punti isolati di $X$}\}$. Quindi $[a+\varepsilon, b-\varepsilon] \cap X$ è finito - se così non fosse, avrebbe un punto di accumulazione 
$\alpha$ che non può essere un punto isolato di $X$ (altrimenti si avrebbe un assurdo). Per cui $f_{|[a+\varepsilon, b-\varepsilon]}$ è lineare a tratti, e, siccome non ha punti angolosi, è lineare.
\end{proof}

\begin{corollary}
Sia $X^{(n)} = X^{\prime\prime\ldots\footnote{$n$ volte.}}$. Se $X^{(n)} = \emptyset$ per qualche $n \in \NN$, allora per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{corollary}

\begin{proof}
Induzione su $n$.
\end{proof}

Il guaio è che ci sono chiusi numerabili per cui $X^{(n)} \ne \emptyset$, qualunque sia $n$.

\begin{example}
Vogliamo costruire $X$ chiuso e numerabile tale che $X^{(n)} \ne \emptyset$ per ogni $n \in \NN$. Cominciamo col rivedere alcuni esempi già visti.
\end{example}

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/es1.png}
	\end{figure}
\end{center}

Tutti i punti sono isolati, $X^{\prime} = \emptyset$.

\pagebreak

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/es2.png}
	\end{figure}
\end{center}

``Successione con punto limite". Tutti i punti sono isolati salvo $l$, quindi $X^{\prime} = \{l\}$ e $X^{\prime\prime} = \emptyset$.

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/es3.png}
	\end{figure}
\end{center}

``Successione di successioni", $X^{\prime} = \{a_{10}, a_{20}, \ldots, l\}$, $X^{\prime\prime} = \{l\}$ e $X^{\prime\prime\prime} = \emptyset$.\\
Si vede che possiamo proseguire, in qualche modo, costruendo una successione di successioni di successioni, etc. $n$ volte, $X_n$. Avremo $X_n^{(n)} \ne \emptyset$, $X_n^{(n+1)} = \emptyset$. Ora costruiamo 
$X_{\omega}$ fatto così:

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/esomega.png}
	\end{figure}
\end{center}

È chiaro che, per ogni $n$, $X_\omega^{(n)} \ne \emptyset$. D'altro canto, $X_\omega$ soddisfa il \hyperref[unicità]{Fatto 1.5}, perché $f$ deve essere lineare in ciascuno degli intervalli
$[a_n,a_{n+1}]$, perché $X_{n+1}$ soddisfa il \hyperref[unicità]{Fatto 1.5}, quindi ci si riduce al caso della successione.

\begin{exercise}
Perché $X_\omega$ è numerabile?
\end{exercise}

Ora potremmo pensare che, pazienza se $X_\omega$ non si smonta a furia di derivati, sarà un caso particolare. Però adesso, possiamo fare una successione di insiemi come $X_\omega$, chiamiamola $X_{\omega+1}$, e 
una successione di questi $X_{\omega+2}$, etc.\\
Al diavolo, serve un nuovo corollario!

\begin{corollary}
Se $X^{(n)}$ è di ``tipo $X_\omega$", allora per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{corollary}

Ok, questo corollario copre $X_\omega$, $X_{\omega + 1}$, $X_{\omega + 2}$, ma copre anche $X_{\omega \cdot 2}$?
\pagebreak
\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/2omega.png}
	\end{figure}
\end{center}

No: occorre un nuovo corollario.

\begin{corollary}
Se $X^{(n)}$ è di ``tipo $X_{\omega \cdot 2}$", allora per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{corollary}

E poi un altro per $X_{\omega \cdot 3}$, e un altro per $X_{\omega \cdot 4}$, etc.\\
E ora abbiamo finito? No, perché possiamo costruire una nuova successione con $X_{\omega},X_{\omega \cdot 2},X_{\omega \cdot 3}$, etc.\\
Se chiamiamo questa follia $X_{\omega \cdot \omega}$, ecco che si riparte a fare successioni di $X_{\omega \cdot \omega}$. Ora si sarà capito che definiremo
una serie aritmetica di queste cose, per cui potremo fare anche $\omega^\omega$, $\omega^{\omega^{\omega}}$, etc. È questa la soluzione allora?\\
No, ogni sforzo di trovare l'induzione a capo delle induzioni è vano. Se ho $X_{\omega}$, $X_{\omega^\omega}$, $X_{\omega^{\omega^{\omega}}}$, etc., allora,
ecco che faccio una successione con queste cose, la battezzo in qualche modo - ad esempio, $X_{\varepsilon_0}$ - e si riparte!\\
Per smontare ogni possibile insieme chiuso e numerabile occorre un \textbf{nuovo tipo di induzione}, l'\vocab{induzione transfinita}, che è strettamente più potente dell'induzione aritmetica.
Questa tecnica è stata sviluppata da Cantor, forse prendendo le mosse dal problema degli insiemi di unicità, e sarà uno degli argomenti centrali del corso.

\begin{exercise}[per la fine del corso]
Dimostrare il teorema di \hyperref[CL]{Cantor-Lebesgue}.
\end{exercise}

\subsection{Giochi di parole}
Descrivere un oggetto matematico non basta per crearlo. Se bastasse, si incorrerebbe in contraddizioni come queste.
\paragraph*{Paradosso di Russell}\mbox{}\\
Tipicamente le collezioni - uso questa parola perché daremo, al termine ``insieme", un senso tecnico preciso - non sono membro di se stesse: la collezione di 
tutti i numeri primi non è un numero primo. Però ci sono anche collezioni che sono membri di se stessi: per esempio la collezione di tutte le collezioni. Consideriamo:
\[ N = \{\text{collezioni $X$}\, | X \not\in X \}
	\]
la collezione delle collezioni che non sono membri di se stessi - la $N$ sta per collezioni normali. Quindi ci chiediamo se $N \in N$ oppure no? $N \in N$ se e solo se per definizione $N \not \in N$, che è assurdo.\\
Il paradosso di Russell ci dice che, del principio di collezione - ossia l'idea che data una proprietà ben definita $P$ si possa costruire la collezione $\{X | P(X)\}$ - non ci si può fidare.

\paragraph*{Paradosso di Berry}\mbox{}\\
L'italiano annovera un numero finito di parole, è quindi possibile formare solo un numero finito di frasi di meno di centro parole. Alcune di queste descrivono un numero naturale, altre no. Comunque, solo un numero 
finito di numeri naturali può essere descritto con meno di cento parole. Per il principio del minimo, esiste:
\begin{align*}
	h = \text{``il più piccolo numero naturale che l'italiano non può} \\ 
 \text{descrivere con meno di cento parole"}
\end{align*}
Il guaio chiaramente, è che lo abbiamo appena descritto con sedici parole.\\
Quindi non ci si può fidare troppo neppure dell'italiano, o meglio, non è possibile descrivere precisamente cosa sia una descrizione precisa.\\
In conclusione, occorre fissare un linguaggio formale in cui si esprimano le proposizioni della teoria degli insiemi, e occorre fissare un sistema di assiomi, espressi in questo linguaggio, che 
dicano quali costruzioni sono lecite: quali insiemi esistono. Il ruolo della teoria degli insiemi è, poi, di fondare l'edificio della matematica. L'ambizione, quindi, è che il linguaggio e gli assiomi della teoria degli insiemi, 
siano in realtà, il linguaggio e gli assiomi della matematica.

\subsection{Scopi del corso}
Questo corso persegue due obiettivi:
\begin{enumerate}[(1)]
	\item Studiare i \textbf{fondamenti della matematica}, nella forma più comunemente accettata nel XX secolo e fino ad ora, la teoria degli insiemi di 
	\href{https://it.wikipedia.org/wiki/Ernst_Zermelo}{\textcolor{purple}{Zermelo}}-\href{https://it.wikipedia.org/wiki/Adolf_Abraham_Halevi_Fraenkel}{\textcolor{purple}{Fraenkel}} con l'assioma della scelta (ZFC).
	\item Studiare tecniche e strumenti che sono stati sviluppati grazie alla teoria degli insiemi, per esempio: la teoria delle cardinalità, la teoria dei numeri ordinali, l'induzione e la ricorsione transfinita.
\end{enumerate}

In questo corso non ci occupiamo dei modelli della teoria degli insiemi. Mi spiego. Per esempio, in teoria dei gruppi si assiomatizza cosa sia un gruppo, e poi si studia come possano essere fatti i diversi gruppi. In 
teoria degli insiemi si assiomatizza l'universo di tutti gli insiemi, però, per il teorema di incompletezza di \href{https://it.wikipedia.org/wiki/Kurt_G%C3%B6del}{\textcolor{purple}{Gödel}}, questa assiomatizzazione non 
può essere completa. Quindi esistono tanti universi insiemistici possibili. Indagare queste possibilità - i modelli della teoria degli insiemi - è argomento di corsi più avanzati.

\newpage
\section{Il linguaggio della teoria degli insiemi}
Per non incorrere in contraddizione, accettiamo che le sole proposizioni ad avere senso siano quelle esprimibili mediante \vocab{formule insiemistiche}. Le formule si costruiscono ricorsivamente.
\begin{itemize}
	\item Le lettere $a,b,c,\ldots,A,B,C,\ldots,\alpha,\beta,\gamma,\ldots$ rappresentano \vocab{variabili}. I valori delle variabili sono sempre insiemi, e non ci sono altri oggetti salvo gli insiemi.
	\item Le \vocab{formule atomiche} sono:
	\[ \text{variabile = variabile} \qquad \qquad \text{variabile $\in$ variabile}\footnote{\,``appartiene a".}
		\]
	sono formule atomiche $x=y$, $x=x$, $\alpha = C$, e anche $x \in y$, $x \in x$, $\alpha \in C$.
	\item Le formule atomiche si combinano tra loro mediante:
	\begin{itemize}
		\item \vocab{connettivi logici} ovvero il ``non'' la ``e'' e la ``o'' (inclusiva):
		\[ \text{$\neg$ formula} \qquad \text{formula $\land$ formula} \qquad \text{formula $\lor$ formula}
			\]
		quindi ad esempio:
		\begin{flalign*}
			&\neg\Phi \equiv \text{``$\Phi$ è falsa''} &\\
			&\Phi \land \psi \equiv \text{``$\Phi$ e $\psi$ sono entrambe vere''} &\\
			&\Phi \lor \psi \equiv \text{``almeno una fra $\Phi$ e $\psi$ è vera''}
		\end{flalign*}
		\item \vocab{quantificatori} ovvero quello universale ``per ogni'' e quello esistenziale ``esiste'':
		\[ \forall x \, \text{formula} \qquad \exists x \, \text{formula}
			\]
		ad esempio:
		\begin{flalign*}
			&\forall x \, \Phi \equiv \text{``$\Phi$ è vera qualunque sia l'insieme $x$''} &\\
			&\exists x \, \Phi \equiv \text{``c'è un insieme $x$ che fa si che $\Phi$ sia vera''}
		\end{flalign*}
		\begin{exercise}
			Chiaramente varranno $\forall x \, x = x,$ $ \forall x \, \exists y \, x = y,$ $ \neg \exists x \, \forall y \, x = y$.
		\end{exercise}
	\end{itemize}
\end{itemize}

\textbf{\underline{L'intuizione}} è che l'universo insiemistico sia un gigantesco grafo diretto (aciclico) i cui vertici sono gli insiemi,
ed in cui le frecce rappresentano la relazione di appartenenza.

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=10.5cm]{immagini/graf.png}
	\end{figure}
\end{center}

Possiamo solo fare affermazioni a proposito di vertici e frecce di questo grafo. Per esempio:
\[ \text{``$a$ è un elemento di un certo $b$''} \equiv \text{``c'è un percorso di due frecce fra $a$ e $b$''} 
	\]
che corrisponde mediante formule insiemistiche a $ \exists x \, a \in x \land x \in b$. E ancora:
\[\text{``$a$ è un sottoinsieme di $b$''} \equiv \text{``ogni elemento di $a$ è elemento di $b$''} \equiv \]\[
		\equiv\text{``non c'è un insieme che è elemento di $a$ e non di $b$''}\equiv\]\[
	 \equiv \text{``non c'è un vertice con una freccia verso $a$ e non una verso $b$''}
	\]
che corrisponde mediante formule insiemistiche a $\neg\exists x \, x \in a \land \neg x \in b$ (tutto ciò che raggiunge $a$ deve raggiungere anche $b$).\\
\textbf{\underline{Parentesi}} Ad essere precisi, avremmo dovuto definire le formule includendo un mucchio di parentesi, allo scopo di eliminare ogni possibilità
di formare una combinazione di simboli ambigua. Per esempio $\textcolor{red}{\Phi_1 \land \Phi_2 \lor \Phi_3}$ è ambigua, perché si potrebbe leggere $(\Phi_1 \land \Phi_2) \lor \Phi_3$
o $\Phi_1 \land (\Phi_2 \lor \Phi_3)$. In una notazione completamente parentesizzata, per esempio, la formula per ``$a$ è un sottoinsieme di $b$'' sarebbe:
\[ \neg(\exists x((x \in a)\land(\neg(x \in b))))
	\]
Non useremo, in generale, questa notazione, ma useremo le parentesi selettivamente per evitare ambiguità.\\
\textbf{\underline{Abbreviazioni}} Le formule appena descritte costituiscono il linguaggio della teoria degli insiemi \textbf{puro}. Durante il corso estenderemo
più volte questo linguaggio mediante abbreviazioni, che semplicemente rimpiazzano formule più lunghe con scritture convenzionali più compatte, e quindi non alterano 
la potenza espressiva del linguaggio. Vediamo le prime abbreviazioni:
\[ x \ne y \Mydef \neg x = y \footnote{Cioè ``non è vero che $x$ è uguale a $y$''.} \qquad x \not\in y \Mydef \neg x \in y \qquad \not\exists x \,\Phi \Mydef \neg \exists x \, \Phi
	\]\[ \Phi \rightarrow \psi \Mydef \psi \lor \neg \Phi \qquad \Phi \leftrightarrow \psi \Mydef (\Phi \rightarrow \psi) \land (\psi \rightarrow \Phi)
		\]\[ \exists x \in y \; \Phi \Mydef \exists x (x \in A \land \Phi) \qquad \forall x \in A \; \Phi \Mydef \forall x (x \in A \rightarrow \Phi)
			\]\[ \exists !\, x\, \Phi(x) \Mydef \exists x (\Phi(x) \land \forall y(\Phi(y) \rightarrow y = a))
				\]\[ \exists !\, x \in A \,\Phi(x) \Mydef \exists! \, x(x \in A \land \Phi(x))
					\]\[ A \subseteq B \Mydef \forall x (x \in A \rightarrow x \in B) \qquad A \subsetneq B \Mydef( A \subseteq B) \land (A \ne B)
						\]\[ C = A \cup B \Mydef \forall x \, x \in C \leftrightarrow (x \in A \lor x \in B)
							\]\[ C = A \cap B \Mydef \forall x \, x \in C \leftrightarrow (x \in A \land x \in B)
								\]
\begin{note}
	Il fatto che possiamo dire $C = A \cup B$ o $C = A \cap B$ non significa né che questi oggetti esistano né che siano unici. Dimostreremo fra poco l'esistenza e unicità 
	di unione e intersezione.
\end{note}

\begin{exercise}
Esprimi queste proposizioni mediante formule insiemistiche pure:
\begin{itemize}
	\item gli elementi degli elementi di $A$ sono elementi di $A$;
	\item $B$ è l'insieme dei sottoinsiemi di $A$;
	\item l'unione degli elementi di $A$ è l'intersezione di quelli di $B$\footnote{Qui assumi che l'unione e intersezione esistano e siano uniche.}
\end{itemize}
\end{exercise}

\subsection{Le regole di inferenza}
La teoria assiomatica degli insiemi si compone di tre parti: il linguaggio formale che abbiamo appena descritto, gli assiomi della teoria che studieremo durante il corso, 
ed un sistema di regole che specificano precisamente quali passaggi sono leciti nelle dimostrazioni. Possiamo immaginare questa ultima componente come una specie di algebra dei ragionamenti,
che permette di verificare i passaggi di una dimostrazione in maniera puramente meccanica, come se fossero semplici manipolazioni algebrica. Noi non vedremo le regole di inferenza, e voglio spiegare qui il perché.
\begin{enumerate}[1]
	\item Sono argomento del corso di logica.
	\item In realtà, scrivere le dimostrazioni in maniera formale, le renderebbe lunghissime e particolarmente incomprensibili.
	\item In pratica, non si sbaglia facendo ragionamenti che non reggono, si sbaglia dicendo cose fumose che non possono essere espresse nel linguaggio della teoria. Per esempio, le parole ``e così via'' sono pericolose.
	\item Conoscere le regole - fidatevi - non aiuta né a trovare né a capire le dimostrazioni.
\end{enumerate}
Pur senza dare un sistema completo di regole, vediamo qualche manipolazione formale che potrebbe servire.\\
\textbf{\underline{Tavole di verità}} Due combinazioni mediante connettivi logici ($\neg$, $\land$, $\lor$, $\rightarrow$, $\leftrightarrow$)
delle stesse formule - ``\vocab{combinazioni booleane}'' - alle volte, dicono la stessa cosa. Per esempio, $\neg \Phi \lor \neg \psi \equiv\footnote{\,``equivale a''.} \neg (\Phi \land \psi)$.
Per verificare questo fatto basta considerare tutte le possibili combinazioni di valori di verità che possono assumere le formule combinate - nell'esempio $\Phi$ e $\psi$ - compilando una ``\vocab{tabella di verità}''.
\begin{center}
	\begin{tabular}{>{$}l<{$}>{$}l<{$}|*{7}{>{$}l<{$}}}
	\Phi & \psi & \neg\Phi   & \neg\psi   & \neg\Phi \lor \neg\psi   & \Phi \land \psi & \neg(\Phi \land \psi)    \\
	\hline\vrule height 14pt width 0pt
	V & V & F & F & \textcolor{red}{F} & V & \textcolor{red}{F}\\
	V & F & F & V & \textcolor{red}{V} & F & \textcolor{red}{V}\\
	F & V & V & F & \textcolor{red}{V} & F & \textcolor{red}{V}\\
	F & F & V & V & \textcolor{red}{V} & F & \textcolor{red}{V}
	\end{tabular} 
\end{center}
Come si osserva le due colonne corrispondenti ai valori di verità delle nostre formule iniziali hanno gli stessi valori di verità in ogni caso.\\
Conviene tenere a mente alcune delle equivalenze elementari:
\[ \neg\neg \Phi \equiv \Phi \qquad \Phi \land (\psi \lor \Theta) \equiv (\Phi \land \psi) \lor (\Phi \land \Theta) \qquad \Phi \lor (\psi \land \Theta) \equiv (\Phi \lor \psi) \land (\Phi \lor \Theta)
	\]\[ \neg(\Phi \land \psi) \equiv \neg \Phi \lor \neg \psi \qquad \neg(\Phi \lor \psi) = \neg \Phi \land \neg \psi
		\]\[ \Phi \rightarrow \neg \psi \equiv \psi \rightarrow \neg \Phi \qquad \Phi \rightarrow \psi \equiv \neg \psi \rightarrow \neg \Phi
			\]

\begin{exercise}
Dimostrare le equivalenze delle formule elencate sopra.
\end{exercise}

Per quanto riguarda i quantificatori ricordiamo le regole seguenti, che tuttavia non sono esaustive.
\[ \neg\forall x \, \Phi \equiv \exists x \, \neg\Phi \qquad \neg\forall x \, \neg \Phi \equiv \exists x \, \Phi
	\]\[ \neg\exists x \, \Phi \equiv \forall x \, \neg \Phi \qquad \neg \exists x \, \neg \Phi \equiv \forall x \, \Phi
		\]

\begin{exercise}
Convinciti della validità delle equivalenze precedenti.
\end{exercise}

\begin{exercise}
Dimostra che:
\[ \neg \forall x \in A \, \Phi \equiv \exists x \in A \, \neg \Phi \qquad \neg \exists x \in A \, \Phi \equiv \forall x \in A \, \Phi
	\]
\end{exercise}

\begin{exercise}
Dimostra che:
\[ \forall x (x \in A \rightarrow x \in B) \equiv \neg \exists x (x \in A \land \neg x \in B)
	\]
\end{exercise}

\begin{exercise}
Secondo te, la seguente formula è vera?
\[ \forall A ((\exists x \, x \in A) \rightarrow \exists x \in A (x \in B \rightarrow \forall y \in A \, y \in B))
	\]
\end{exercise}

Infine vi sono regole per la relazione di uguaglianza, che dicono, in sostanza, che se $x = y$ allora $x$ e $y$ non sono distinguibili, ossia vale $\Phi(x) \leftrightarrow \Phi(y)$ qualunque sia $\Phi$.
Per quanto ci riguarda, \textbf{se $x = y$ allora $x$ e $y$ sono nomi della stessa cosa}.

\newpage
\section{I primi assiomi}
\subsection{Assiomi dell'insieme vuoto e di estensionalità}
\begin{axiom}
[Assioma dell'insieme vuoto]
\label{ax1}
Esiste un insieme vuoto.
\[ \exists x \; \forall y \; y \not\in x
		\]
\end{axiom}

\begin{note}
Questo assioma non sarebbe strettamente necessario, in quanto potremmo ottenere un insieme vuoto anche come sottoprodotto, per esempio, dell'assioma dell'infinito che vedremo in seguito.
Tuttavia è bello poter partire avendo per le mani almeno un insieme.
\end{note}

\begin{axiom}
[Assioma di estensionalità]
\label{ax2}
Un insieme è determinato dalla collezione dei suoi elementi. Due insiemi coincidono se e solo se hanno i medesimi elementi.
\[ \forall a \; \forall b \; a = b \leftrightarrow \forall x (x \in a \leftrightarrow x \in b)
	\]
\end{axiom}

\begin{exercise}
Dimostra che la freccia $a = b \rightarrow \forall x (x \in a \leftrightarrow x \in b)$, in realtà, segue dal fatto che se $a = b$ allora $a$ e $b$ sono indistinguibili\footnote{Nel senso che abbiamo descritto in precedenza, cioè sono nomi della stessa cosa.}.
\end{exercise}

\textbf{\underline{Convenzione}} Le variabili libere (= non quantificate), se non specificato altrimenti, si intendono quantificate universalmente all'inizio della formula. Per cui possiamo scrivere
l'assioma di estensionalità semplicemente nella forma:
\[ a = b \leftrightarrow \forall x (x \in a \leftrightarrow x \in b)
	\]

\begin{proposition}[Unicità dell'insieme vuoto]
C'è un unico insieme vuoto.
\[ \exists ! \; x \; \forall y \; y \not \in x
	\]
\end{proposition}

\begin{proof}
Consideriamo due insiemi vuoti $x_1$ e $x_2$, ossia supponiamo $\forall y \, y \not\in x_1$, e $\forall y \, y \not \in x_2$. Allora:
\[ \forall y (y \in x_1 \leftrightarrow y \in x_2)
	\]
[sono coimplicate logicamente] perché $y \in x_1$ e $y \in x_2$ sono entrambe necessariamente false. Quindi, per \hyperref[ax2]{estensionalità}, la proposizione sopra è equivalente a $x_1 = x_2$.\\
\emph{Dimostrazione formale.} Questo livello di pedanteria non è necessario, ma, per una volta, proviamo a dimostrare in ogni dettaglio la formula $\exists ! \, \forall y \, y \not\in x$. Per definizione di $\exists !$, ciò equivale a:
\[ \exists x_1 ((\forall y \, y \not \in x_1) \land \forall x_2 ((\forall y \, y \not \in x_2) \rightarrow x_2 = x_1))
	\]
Per l'\hyperref[ax1]{assioma del vuoto}, $\exists x_1 \, \forall y \, y \not \in x_1$: fissiamo questo $x_1$. Resta da dimostrare che:
\[ (\forall y \, y \not \in x_1) \land \forall x_2(\forall y \, y \not \in x_2) \rightarrow x_2 = x_1
	\]
Per costruzione, $\forall y \, y \not\in x_1$, è vera (avendo fissato $x_1$), quindi resta:
\[ \forall x_2 (\forall y \, y \not \in x_2) \rightarrow x_2 = x_1
	\]
Ora prendiamo un $x_2$ qualunque, dobbiamo dimostrare:
\[ \forall y (y \not \in x_2) \rightarrow x_2 = x_1
	\]
Si danno due casi: o $\forall y (y \not \in x_2)$ è vera o è falsa. Nel secondo caso, l'implicazione è vera per via della tabella di verità. Nel primo abbiamo sia $\forall y \, y \not \in x_1$, [vera] per
costruzione, sia $\forall y \, y \not \in x_2$, [vera] per ipotesi. Quindi, preso un qualunque $y$, $y \in x_1$ e $y \in x_2$ sono entrambe false. La tabella di verità di $\leftrightarrow$ ci dice quindi che vale $y \in x_1 \leftrightarrow y \in x_2$, e, per 
l'arbitrarietà di $y$:
\[ \forall y (y \in x_1 \leftrightarrow y \in x_2)
	\]
Dall'\hyperref[ax2]{assioma di estensionalità}:
\[ \forall y (y \in x_1 \leftrightarrow y \in x_2) \rightarrow x_1 = x_2
	\]
Abbiamo quindi $x_1 = x_2$, da cui segue la verità dell'implicazione iniziale.
\end{proof}

Chiaramente, ho voluto scrivere questa dimostrazione delirante per convincervi che NON È UNA BUONA IDEA.

\begin{notation}
L'unicità dell'insieme vuoto ci giustifica ad introdurre una nuova abbreviazione:
\[ x = \emptyset \Mydef \forall y \, y \not\in x \qquad \emptyset \in x \Mydef \exists z (z = \emptyset \land z \in x)
	\]
\end{notation}

\subsection{Assioma di separazione}
\begin{axiom}
[Assioma di separazione]
\label{ax3}
Se $A$ è un insieme, e $\psi(x)$ una formula insiemistica qualunque, allora $\{x \in A | \psi (x)\}$\footnote{Stiamo usando già questa notazione, ma la definiremo a breve.} è un insieme.
\[ \forall A \; \exists B \; \forall x \; x \in B \leftrightarrow (x \in A \land \psi (x))
	\]
\end{axiom}

\begin{note}
Tecnicamente l'assioma di separazione è uno \vocab{schema di assiomi}, ossia una regola che, per ogni possibile formula $\psi$, ci permette di scrivere un assioma.
\end{note}

\begin{proposition}
Fissati $A$ e $\psi(x)$, l'insieme $\{x \in A | \psi(x)\}$ è univocamente definito. Ossia:
\[ \forall A \; \exists \textcolor{red}{!} B \; \forall x \; x \in B \leftrightarrow (x \in A \land \psi(x))
	\]
\end{proposition}

\begin{proof}
Come per l'unicità dell'insieme vuoto, supponiamo di avere $B_1$ e $B_2$ tali che:
\[ \forall x \, x \in B_1 \leftrightarrow (x \in A \land \psi(x)) \qquad \forall x \, x \in B_2 \leftrightarrow (x \in A \land \psi(x))
	\]
Allora, $\forall x \, x \in B_1 \leftrightarrow (x \in A \land \psi(x)) \leftrightarrow x \in B_2$, quindi, \hyperref[ax2]{estensionalità}, $B_1 = B_2$.
\end{proof}

\begin{exercise}
Verifica che se $\psi \leftrightarrow \Phi$ e $\Phi \leftrightarrow \Theta$, allora $\psi \leftrightarrow \Theta$.
\end{exercise}

\begin{notation}
Vista l'unicità, scriviamo:
\[ B = \{x \in A | \psi(x)\} \Mydef \forall x \, x \in B \leftrightarrow (x \in A \land \psi(x))
	\]
\end{notation}

Osserviamo che l'assioma di separazione è una forma indebolita del principio di collezione. Rimpiazzando questo con quello, il Paradosso di Russell diventa una proposizione.

\begin{proposition}[Insieme di tutti gli inisemi]
Non esiste l'insieme di tutti gli insiemi.
\[ \not\exists V \; \forall x \; x \in V
	\]
\end{proposition}

\begin{proof}
Supponiamo, per assurdo, che esista questo $V$. Allora, per \hyperref[ax3]{separazione} con la formula $\psi (x) \equiv x \not \in x$, esiste:
\[ N = \{x \in V | x \not\in x\}
	\]
che ha, per definizione, la proprietà:
\[ \forall x \, x \in N \leftrightarrow (x \in V \land x \not \in x)
	\]
Per ipotesi assurda, $x \in V$ è sempre vera (stiamo considerando l'insieme di tutti gli insiemi), quindi quanto scritto si riduce a:
\[ \forall x \, x \in N \leftrightarrow x \not\in x
	\]
prendendo ora, $x = N$, abbiamo $N \in N \leftrightarrow N \not\in N$, assurdo.
\end{proof}

\subsection{Classi e classi proprie}
Sebbene, abbiamo detto che gli unici oggetti della teoria degli insiemi sono gli insiemi, usualmente ci si riferisce alla collezione di tutti gli insiemi 
che soddisfano una certa formula come ad una specie di insieme: una \vocab{classe}. Più precisamente, data una formula $\psi(x)$, se diciamo: ``sia $C$ la classe degli insiemi $x$ tali che $\psi(x)$''
intendiamo dire che useremo la scrittura $x \in C$ come una semplice abbreviazione per la formula $\psi(x)$. \\
Non avrebbe senso scrivere \textcolor{red}{$C \in$ qualcosa}, perché il simbolo $\in$ in $x \in C$ non ha senso, se non nel tutt'uno $\in C$. In altri termini, se scriviamo $x \in C$ in luogo di $\psi(x)$ è solo come ausilio dell'intuizione:
avremmo potuto decidere di scrivere $x$\ding{168}, o nient'altro che $\psi(x)$.

\begin{definition}
La classe $V$ si dice \vocab{classe universale} ed è la classe di tutti gli insiemi.
\[ x \in V \Mydef x = x
	\]
\end{definition}

Insomma, scrivere $x \in V$ non dice molto: è una formula sempre vera.
\pagebreak
\begin{notation}
Date due classi $C$ e $D$, che, ricordiamo, non significa altro che ``date due formule$\ldots$'', definiamo l'abbreviazione:
$$ C = D \Mydef \forall x ((x \in C) \leftrightarrow (x \in D)) $$
\end{notation}

Ora, dato un qualunque insieme $A$, possiamo definire la classe $\hat{A}$ degli $x$ tali che $x \in A$. Se $\hat{A} = \hat{B}$, per definizione:
\[ \forall x ((x \in A) \leftrightarrow (x \in B))
	\]
quindi $A = B$ per estensionalità. Ha quindi senso, con un leggero abuso di notazione, omettere il cappelletto $\hat{}$ e identificare la classe $\hat{A}$ semplicemente con $A$. In questo senso,
abbiamo classi che sono insiemi - formalmente $C$ è un insieme se $C = \hat{A}$ per qualche insieme $A$ - e classi che non sono insiemi. Chiamiamo \vocab{classe propria} una classe che non è un insieme.

\begin{example}
$V$ è una classe propria.
\end{example}

\textbf{\underline{L'intuizione}}, che sarà più chiara via via che procediamo nel corso, è che le classi proprie sono troppo grandi per essere insiemi.

\subsection{Assioma del paio e coppia di Kuratowski}
I primi assiomi ci dicono, a grandi linee, che, entro i limiti di quanto si può fare rinunciando al principio di collezione - che esiste $\{x | \, \text{una qualunque proprietà}\}$ -, gli insiemi sono delle specie di collezioni.
Sono determinati dai loro elementi, e li si può dividere in collezioni più piccole in maniera arbitraria. Ci troviamo, però, adesso, nella necessità di procurarci qualche insieme con cui lavorare. I prossimi assiomi serviranno per giustificare le costruzioni con cui,
usualmente, si definiscono nuovi insiemi. Per esempio, abbiamo bisogno di costruire certi insiemi di base, tipo l'insieme dei numeri interi o insiemi finiti i cui elementi sono elencati esplicitamente, fare prodotti di insiemi esistenti, 
considerare le funzioni fra insiemi esistenti, etc.

\begin{axiom}
[Assioma del paio]
\label{ax4}
Dati $a$ e $b$ esiste l'insieme $\{a,b\}$.
\[ \forall a \; \forall b \; \exists P \; \forall x \; x \in P \leftrightarrow (x = a \lor x = b)
	\]
\end{axiom}

\begin{proposition}
[Unicità del paio]
Fissati $a$ e $b$, l'insieme $\{a,b\}$ è univocamente determinato.
\[\forall a \; \forall b \; \exists\textcolor{red}{!} P \; \forall x \; x \in P \leftrightarrow (x = a \lor x = b)
	\]
\end{proposition}

\begin{exercise}
	Dimostra la proposizione precedente.
\end{exercise}

\begin{soln}
	Supponiamo che esistano $P_1$ e $P_2$ tali che:
	\[ \forall x (x \in P_1 \leftrightarrow (x = a \lor x = b)) \qquad \text e \qquad \forall x (x \in P_2 \leftrightarrow (x = a \lor x = b))
		\]
	da ciò segue che:
	\[ \forall x (x \in P_1 \leftrightarrow x \in P_2)
		\]
	dunque per \hyperref[ax2]{estensionalità} $P_1 = P_2$\footnote{Volendo essere pignoli andrebbe specificato $\forall P_1 \, \forall P_2$.}.
\end{soln}

\begin{proposition}[Esistenza dei singoletti]
	Dato $a$, esiste ed è unico $\{a\}$.
	\[ \forall a \; \exists ! S \; \forall x \; x \in S \leftrightarrow x = a
		\]
\end{proposition}

\begin{proof}
	Ponendo $b = a$ nella proposizione precedente, si ha che:
	\[ \forall a \; \exists ! S \; \forall x \; x \in S \leftrightarrow (x = a \lor x= a)
		\]
	ora $x = a \lor x = a$ equivale a $x = a$.
\end{proof}

\begin{notation}
	Possiamo ora porre:
	\[ P = \{a,b\} \Mydef \forall x \, x \in P \leftrightarrow (x = a \lor x = b)
		\]\[ S = \{a\} \Mydef \forall x \, x \in S \leftrightarrow x = a
			\]
\end{notation}

\begin{remark}
	Osserviamo che $\{a,b\} = \{b,a\}$.
\end{remark}

\begin{proof}
	Usiamo il fatto che $\lor$ è commutativo:
	\[ x \in \{a,b\} \leftrightarrow (x = a \lor x = b) \leftrightarrow (x = b \lor x = a) \leftrightarrow x \in \{b,a\}
		\]
	quindi per \hyperref[ax2]{estensionalità} $\{a,b\} = \{b,a\}$.
\end{proof}

Il paio $\{a,b\}$ è, quindi, una coppia non ordinata. È possibile codificare le coppie ordinate con questo trucco.

\begin{definition}
	[Coppia di \href{https://it.wikipedia.org/wiki/Kazimierz_Kuratowski}{\textcolor{purple}{Kuratowski}}]
	Si dice \vocab{coppia di Kuratowski}:
	\[(a,b) \Mydef \{a,\{a,b\}\}
		\]
\end{definition}

\begin{proposition}
	La coppia di Kuratowski $(a,b)$ rappresenta la coppia ordinata di $a$ e $b$, ossia:
	\[ (a,b) = (a^{\prime},b^{\prime}) \leftrightarrow (a = a^{\prime} \land b = b^{\prime})
		\]
\end{proposition}

\begin{proof}
	Dato $c = (a,b)$, vogliamo determinare univocamente $a$ e $b$. Intanto, $a$ è determinato da:
	\[ x = a \leftrightarrow \forall y \in c \,(x \in c)
		\]
	la freccia $\rightarrow$ è immediata [per come è definita $(a,b)$]\footnote{Se $x$ è $a$, allora,
	poiché qualsiasi elemento che appartenga alla coppia o è $\{a\}$ o contiene $a$, $x$ deve appartenere a quest'ultimo.},
	mentre $\leftarrow$ segue da $\{a\} \in c$, per cui $\forall y \in c \, (x \in y) \implies x \in \{a\} \implies x = a$.
	Veniamo ora a $b$. Studiamo prima il caso in cui $\exists ! x \, x \in c$:
	\[ \exists x \, x \in c \iff \{a\} = \{a,b\}
		\]
	in quanto $\{a\} \in c$ e $\{a,b\} \in c$, quindi $\{a\} = \{a,b\} \iff b = a$, per \hyperref[ax2]{estensionalità}. In questo caso, $b$ è quindi determinato.
	Altrimenti, $x = \{a,b\} \leftrightarrow (x \in c \land x \ne \{a\})$, $\{a,b\}$ è quindi univocamente determinato da $c$, e $x = b \leftrightarrow (x \in \{a,b\} \land x \ne a)$.
\end{proof}

\begin{definition}
	Possiamo definire quindi:
	\[ (a,b,c) \Mydef ((a,b),c)
		\]\[ (a,b,c,d) \Mydef (((a,b),c),d)
			\]\[ (a_1,a_2,\ldots,a_n) \Mydef ((a_1,a_2,\ldots,a_{n-1}),a_n)
				\]
\end{definition}

\begin{note}
	Quest'ultima definizione è, in realtà, uno schema di definizioni: una per ogni $n$. Per ora, \textcolor{red}{NON} siamo in grado di scrivere, per esempio,
	una formula insiemistica che dica ``Esiste un $n$ ed una $n$-upla $(a_1,\ldots,a_n)$ tale che…''. Però, per ogni $n$ dato, chessò 92, possiamo scrivere esplicitamente una formula che dice $x = (a_1,a_2,a_3,\ldots,a_{92})$.
\end{note}

\begin{proposition}
	Si ha che:
	\[ (a,b,c) = (a',b',c') \leftrightarrow a = a' \land b = b' \land c = c'
		\]\[ (a_1,\ldots,a_n) = (a_1',\ldots,a_n') \leftrightarrow a_1 = a_1' \land \ldots \land a_n = a_n'
			\]
\end{proposition}

\begin{exercise}
	Dimostra la prima e convinciti che, dato un qualunque $n$ esplicito, potresti dimostrare la seconda.
\end{exercise}

\subsection{Assioma dell'unione e operazioni booleane}

\begin{axiom}[Assioma dell'unione]
	\label{ax5}
	Dato un insieme $A$ esiste un insieme $B$ i cui elementi sono gli elementi degli elementi di $A$. Ovvero, dato un insieme $A$ esiste l'unione degli elementi di $A$.
	\[ \forall A \; \exists B \; \forall x \; x \in B \leftrightarrow \exists y \in A \; x \in y\footnote{Cioè $x$ è un elemento di $B$ se e solo se è un elemento di un elemento di $A$.}
		\]
\end{axiom}

\begin{proposition}
	[Unicità dell'unione]
	Vale l'unicità dell'unione:
	\[ \forall A \; \exists ! B \; \forall x \; x \in B \leftrightarrow \exists y \in A \; x \in y
		\]
\end{proposition}

\begin{proof}
	Supponiamo di avere $B_1$ e $B_2$ tali che:
	\[ \forall x \, x \in B_1 \leftrightarrow \exists y \in A \, x \in y
		\]\[ \forall x \, x \in B_2 \leftrightarrow \exists y \in A \, x \in y
			\]
	quindi $\forall x (x \in B_1 \leftrightarrow x \in B_2)$, e per \hyperref[ax2]{estensionalità} $B_1 = B_2$.
\end{proof}

\begin{notation}
	Possiamo introdurre l'abbreviazione:
	\[ B = \bigcup A\footnote{``Unione di $A$''.} \Mydef \forall x \,( x \in B \leftrightarrow \exists y \, x \in y)
		\]
\end{notation}

\begin{exercise}
	Dimostra che dall'assioma dell'unione segue che:
	\[ \forall A \; \exists B \; (\forall y \in A \; \forall x \in y \; x \in B)\footnote{Cioè per ogni insieme esiste l'insieme di tutti gli elementi degli elementi di $A$.}
		\]
\end{exercise}

Combinando l'assioma dell'unione e del paio possiamo definire $a \cup b$.

\begin{definition}
	Poniamo:
	\[ a \cup b \Mydef \bigcup\{a,b\}
		\]
\end{definition}

\begin{proposition}
	Vale che:
	\[ x \in a \cup b \leftrightarrow (x \in a \lor x \in b)
		\]
\end{proposition}

\begin{proof}
	Dire che $x$ è un elemento di $a \cup b$ significa dire che $x$ è un elemento di un elemento di $\{a,b\}$, ossia
	che $x$ è un elemento di uno fra $a$ e $b$ [il viceversa è ovvio per la definizione che abbiamo dato di unione].
\end{proof}

Ora definiamo le intersezioni: riesci a vedere perché, a differenza delle unioni, non servirà un nuovo assioma?

\begin{definition}
	Sia $C$ una \textcolor{red}{classe}\footnote{Quindi, in particolare, $C$ può essere un insieme (in questo caso la definizione è lecita in generale con le classi, i cui elementi sono insiemi).} non vuota.
	L'\textcolor{red}{insieme} $B$ è l'\vocab{intersezione} di $C$ se:
	\[ B = \bigcap C \Mydef \forall x \; x \in B \leftrightarrow \forall y \in C \; x \in y
		\]
\end{definition}

\begin{proposition}
	Data una classe non vuota $C$, l'intersezione $\bigcap C$ esiste ed è unica. In particolare, nel caso dell'intersezione di un insieme vale:
	\[ \forall A (A \ne \emptyset \rightarrow \exists ! B \; \forall x(x \in B \leftrightarrow \forall y \in A \; x \in y))
		\]
\end{proposition}

\begin{note}
	L'ipotesi $C \ne \emptyset$ è necessaria perché si avrebbe che $\bigcap \emptyset$ è la classe universale $V$, che non è un insieme.
\end{note}

\begin{proof}
	L'unicità segue per \hyperref[ax2]{estensionalità} al solito modo. Veniamo all'esistenza. Dal momento che $C$ non è vuota, possiamo prendere $z \in C$. 
	Ora consideriamo:
	\[ B = \{x \in z | \forall y \in C \, x \in y\}
		\]
	chiaramente $x \in B \rightarrow \forall y \in C \, x \in y$. D'altro canto, $\forall y \in C \, x \in y$ implica, in particolare, $x \in z$, quindi $x \in B$. Abbiamo 
	così verificato che $x \in B \leftrightarrow \forall y \in C \, x \in y$, ossia $B = \bigcap C$.
\end{proof}

\begin{notation}
	Poniamo:
	\[ a \cap b \Mydef \bigcap\{a,b\} \qquad \text e \qquad a\setminus b \Mydef \{x \in a | x \not\in b\}
		\]
\end{notation}

\begin{proposition}
	Vale che:
	\[ x \in a \cap b \leftrightarrow (x \in a \land x \in b)
		\]\[ x \in a \setminus b \leftrightarrow (x \in a \land x \not\in b)
			\]
\end{proposition}

\begin{exercise}
	Dimostrare la proposizione precedente (la seconda è semplicemente la definizione).
\end{exercise}

\begin{proposition}
	Alcune proprietà delle operazioni $\cup$, $\cap$, $\setminus$:
	\[ \text{\textcolor{red}{commutatività:}} \qquad a \cup b = b \cup a \qquad \text e \qquad a \cap b = b \cap a
		\] \begin{align*}	\text{\textcolor{red}{associatività:}} \qquad  
			&a \cup (b \cup c) = (a \cup b) \cup c \Mydef a \cup b \cup c\\
			&a \cap (b \cap c) = (a \cap b) \cap c \Mydef a \cap b \cap c
		\end{align*}
	\begin{align*}	\text{\textcolor{red}{distributività:}} \qquad  
		&a \cup (b \cap c) = (a \cup b) \cap (a \cup c)\\
		&a \cap (b \cup c) = (a \cap b) \cup (a \cap c)
	\end{align*}
	\begin{align*}	\text{\textcolor{red}{leggi di \href{https://it.wikipedia.org/wiki/Augustus_De_Morgan}{\textcolor{purple}{De Morgan}}:}} \qquad  
		&a \setminus (b \cup c) = (a \setminus b) \cap (a \setminus c)\\
		&a \setminus (b \cap c) = (a \setminus b) \cup (a \setminus c)
	\end{align*}
\end{proposition}

\begin{proof}
	Tutte queste proprietà su deducono immediatamente dalle corrispondenti proprietà dei connettivi logici, le quali, a loro volta, si vedono con le tabelle di verità. Per esempio, dimostriamo 
	la prima delle leggi di De Morgan:
	\[ \begin{split}
		x \in a \setminus (b \cup c) & \iff x \in a \land x \not\in (b \cup c)\\
		& \iff x \in a \land \neg(x \in b \lor x \in c)\\
		& \iff x \in a \land x \not\in b \land x \not\in c\\
		& \iff x \in a \land x \not\in b \land x \in a \land x \not\in c\\
		& \iff x \in a \setminus b \land x \in a \setminus c\\
		& \iff x \in (a \setminus b) \cap (a \setminus c)
	\end{split}
		\]
\end{proof}

Ora possiamo costruire insiemi finiti elencandone gli elementi, come si fa di solito, con la notazione $\{\ldots\}$.

\begin{notation}
	Poniamo:
	\[ \{a,b,c\} \Mydef \{a\} \cup \{b\} \cup \{c\}
		\]\[ \{a,b,c,d\} \Mydef \{a\} \cup \{b\} \cup \{c\} \cup \{d\}
			\]\[ \{a_1,\ldots,a_n\} \Mydef \{a_1\} \cup \ldots \cup \{a_n\}
				\]
\end{notation}

\begin{proposition}
	Vale che:
	\[ x \in \{a,b,c\} \leftrightarrow (x = a \lor x = b \lor x = c)
		\]\[ x \in \{a_1,\ldots,a_n\} \leftrightarrow (x = a_1 \lor \ldots \lor x = a_n) 
			\]
\end{proposition}

\begin{exercise}
	Dimostrare la proposizione precedente.
\end{exercise}

\subsection{Assioma delle parti e prodotto cartesiano}
Abbiamo definito le coppie $(x,y)$, però, per esempio, ancora nulla ci assicura che dati $A$ e $B$ esista:
\[ A \times B = \{(x,y) | x \in A \land y \in B\}
	\]
Le funzioni $A \longrightarrow B$ saranno poi sottoinsiemi di $A \times B$, e vorremo parlare dell'insieme ${}^{A}B$
delle funzioni $A \longrightarrow B$. Per tutto questo ci manca un solo ingrediente: l'insieme delle parti.

\begin{axiom}
	[Assioma delle parti]
	\label{ax6}
	Dato un insieme $A$ esiste l'insieme $\ps(A)$ i cui elementi sono i sottoinsiemi di $A$.
	\[ \forall A \; \exists B \; \forall x \; x \in B \leftrightarrow x \subseteq A 
		\]
\end{axiom}

\begin{proposition}
	[Unicità delle parti]
	Vale che:
	\[\forall A \; \exists ! B \; \forall x \; x \in B \leftrightarrow x \subseteq A 
		\]
\end{proposition}

\begin{proof}
	Segue come sempre per \hyperref[ax2]{estensionalità}, in quanto, se avessimo $B_1$, $B_2$, allora:
	\[ \forall x (x \in B_1 \leftrightarrow x \subseteq A) \qquad \text e \qquad \forall x(x \in B_2 \leftrightarrow x \subseteq A)
		\]
	quindi $\forall x(x \in B_1 \leftrightarrow x \in B_2) \leftrightarrow B_1 = B_2$.
\end{proof}

\begin{notation}
	Data l'unicità possiamo porre:
	\[ B = \ps(A) \Mydef \forall x \; x \in B \leftrightarrow x \subseteq A
		\]
\end{notation}

\begin{proposition}[Esistenza ed unicità del prodotto cartesiano]
	Dati $A$ e $B$  esiste un unico insieme $A \times B$ tale che:
	\[ \forall z \; z \in A \times B \leftrightarrow \exists x \in A \; \exists y \in B \; z = (x,y)\footnote{Ossia, informalmente, $A \times B = \{(x,y) | x \in A, y \in B\}$.}
		\]
\end{proposition}

\begin{proof}
	L'unicità è conseguenza immediata della definizione e dell'\hyperref[ax2]{assioma di estensionalità}. Per l'esistenza, definiamo:
	\[ A \times B \Mydef \{z \in \ps(\ps(A \cup B)) | \exists x \in A \ \exists y \in B \ z = (x,y)\}
		\]
	dobbiamo dimostrare che ogni coppia $(x,y)$ con $x \in A$ e $y \in B$ appartiene a questo insieme. Basta dimostrare che tutte queste coppie
	appartengono a $\ps(\ps(A \cup B))$:
	\[\begin{split}
		a \in A \land b \in B &\implies \{a\},\{a,b\} \subseteq A \cup B\footnote{Poniamo $a,b,\ldots \in z \Mydef a \in z \land b \in z \land \ldots$ e $a,b,\ldots \subseteq z \Mydef a \subseteq z \land b \subseteq z \land \ldots$.}\\
		& \implies \{a\},\{a,b\} \in \ps(A \cup B)\\
		& \implies (a,b) = \{\{a\},\{a,b\}\} \subseteq \ps(A \cup B)\\
		& \implies (a,b) \in \ps(\ps(A \cup B))
	\end{split}
		\]
\end{proof}

\begin{note}
	Avremmo potuto costruire $A \times B$ usando, anziché l'assioma delle parti, l'assioma del rimpiazzamento, che vedremo più avanti.
\end{note}

\subsection{Relazioni di equivalenza e di ordine, funzioni}
Ora rivedremo alcuni concetti ben noti dai primi corsi del primo anno (o dalla scuola superiore?). Lo facciamo molto rapidamente, essenzialmente per completezza, e per fissare le notazioni.

\begin{definition}
	Una \vocab{relazione binaria} fra $A$ e $B$ è un sottoinsieme di $A \times B$.
\end{definition}

\begin{notation}
	Data una relazione $\rel \subseteq A \times B$, poniamo:
	\[ a \rel b \Mydef (a,b) \in \rel
		\]
\end{notation}

\begin{example}
	Per esempio scriviamo $a < b$ per $(a,b) \in <$.
\end{example}

\begin{definition}
	Una relazione $\sim \,\subseteq A \times A$ è una \vocab{relazione di equivalenza} se è:
	\begin{enumerate}[(i)]
		\item \textbf{\underline{riflessiva}}: $\forall x \in A \; x \sim x$.
		\item \textbf{\underline{simmetrica}}: $\forall x,y \in A\footnote{$\forall x_1,\ldots,x_n \Mydef \forall x_1 \ldots \forall x_n$, e lo stesso con $\exists$ e con i quantificatori limitati.} x \sim y \leftrightarrow y \sim x$.
		\item \textbf{\underline{transitiva}}: $\forall x,y,z \in A \; (x \sim y \land y \sim z) \rightarrow x \sim z$.
	\end{enumerate}
\end{definition}

\begin{definition}
	$\leq \, \in A \times A$ è una \vocab{relazione di ordine (largo)} se è:
	\begin{enumerate}[(i)]
		\item \textbf{\underline{riflessiva}}: $\forall x \in A \; x \leq x$.
		\item \textbf{\underline{antisimmetrica}}: $\forall x,y \in A \; (x \leq y \land y \leq x) \rightarrow x = y$.
		\item \textbf{\underline{transitiva}}: $\forall x,y,z \in A \; (x \leq y \land y \leq z) \rightarrow x \leq z$.
	\end{enumerate}
\end{definition}

\begin{definition}
	$< \, \in A \times A$ è una \vocab{relazione di ordine stretto} se è:
	\begin{enumerate}[(i)]
		\item \textbf{\underline{irriflessiva}}: $\forall x \in A \; \neg(x < x)$.
		\item \textbf{\underline{transitiva}}: $\forall x,y,z \in A \; (x < y \land y < z) \rightarrow x < z$.
	\end{enumerate}
\end{definition}

\begin{exercise}
	Dimostra che una relazione di ordine stretto $<$ su $A$ è automaticamente asimmetrica:
	\[ \forall x,y \in A \; x < y \rightarrow \neg (y < x)
		\]
\end{exercise}

\begin{proposition}
	Data una relazione di ordine stretto $<$ su $A$, la relazione:
	\[ \leq\, = \{(x,y) \in A \times A | x < y \lor x = y\}\footnote{Formalmente: $\{z \in A \times A | \exists x,y \in A \; z = (x,y) \land \ldots\}$.}
		\]
	è una relazione di ordine largo. Viceversa, se $\leq$ è una relazione di ordine largo, la seguente relazione è dei ordine stretto:
	\[ <\, = \{(x,y) \in A \times A | x \leq y \land x \ne y\}\footnote{Come la nota sopra.}
		\]
	Inoltre, in questo modo, le relazioni di ordine stretto e di ordine largo sono poste in corrispondenza una - a - uno.
\end{proposition}

\begin{proof}
	Definiamo la diagonale:
	\[ \Delta_A \Mydef \{(x,y) \in A \times A | x = y\}
		\]
	Allora è facile verificare che, se $<$ è una relazione di ordine stretto, allora $< \cap \,\Delta_A = \emptyset$ e $< \cup \,\Delta_A$ è una relazione di ordine largo corrispondente.
	Viceversa, se $\leq$ è una relazione di ordine largo, allora $\Delta_A \subseteq \, \leq$ e $\leq \setminus \Delta_A$ è la relazione di ordine stretto corrispondente.
\end{proof}

\begin{notation}
	Fissata una relazione di ordine largo $\textcolor{red}{\leq}$ su $A$, ci sentiremo liberi di usare la corrispondente relazione di ordine stretto $\textcolor{red}{<}$ fintanto che la scelta del simbolo sia indizio sufficiente dell'operazione.
	Inoltre scriveremo $x > y$ per $y < x$ e $x \geq y$ per $y \leq x$.
\end{notation}

\begin{definition}
	Una \vocab{relazione di ordine totale} su $A$ è una relazione di ordine $\leq$ tale che:
	\[ \forall x,y \in A \; x \leq y \; \lor x = y \; \lor y \leq x
		\]
\end{definition}

\begin{exercise}
	Formula la definizione precedente per ordini stretti.
\end{exercise}

\begin{definition}
	Data una relazione $\rel \subseteq A \times B$, $A' \subseteq A$ e $B' \subseteq B$, possiamo definire la \vocab{restrizione} di $\rel$ a $A'\times B'$:
	\[ \rel_{|A' \times B'} \Mydef \rel \cap (A' \times B')
		\]
\end{definition}

\begin{exercise}
	Data $\rel$ relazione di equivalenza/ordine su $A$ e $A' \subseteq A$, dimostra che $\rel_{|A' \times A'}$ è una relazione di equivalenza/ordine su $A'$.
\end{exercise}

\begin{definition}
	Data una relazione $\rel \subseteq A \times B$, definiamo:
	\[ \Dom(\rel) \Mydef \{x \in A | \exists y \in B \; x\rel y\} \qquad \text{\vocab{dominio} di $\rel$}
		\]\[ \Imm(\rel) \Mydef \{y \in B | \exists x \in A \; x \rel y \} \qquad \text{\vocab{immagine} di $\rel$}
			\]
\end{definition}

\begin{definition}
	Chiamiamo \vocab{funzione: $A \longrightarrow B$} una relazione $f \subseteq A \times B$ tale che:
	\[ \forall x \in A \; \exists ! \, y \in B \; (x,y) \in \rel\footnote{Intuitivamente $f$ è l'insieme delle coppie $(x,f(x))$ per $x \in A$.}
		\]
\end{definition}

\begin{notation}
	Data una funzione $f$, scriviamo:
	\[ y = f(x) \Mydef (x,y) \in f
		\]
	Dato $S \subseteq \Dom(f)$, scriviamo:
	\[ f[S] \Mydef \{y \in \Imm(f)| \exists x \in S \; y = f(x)\} = \underbrace{\{f(x) | x \in S\}}_{\text{informalmente}}
		\]
\end{notation}

\begin{definition}
	Una funzione $f: A \longrightarrow B$ è:
	\[ \begin{split}
		\text{\vocab{iniettiva} se:}\; & \forall y \in \Imm(f)\; \exists! \, x \in \Dom(f) \; f(x) = y\\
		\text{\vocab{suriettiva} se:}\; & B = \Imm(f)\; \text{ossia $\forall y \in B \; \exists x \in A \; f(x) = y$.}\\
		\text{\vocab{bigettiva} se:}\; &\text{è sia iniettiva sia surgettiva.}
	\end{split}
		\]
\end{definition}

\begin{definition}
	Data $f$ iniettiva:
	\[ f^{-1} \Mydef \{(y,x) \in B \times A | f(x) = y\}
		\]
\end{definition}

\begin{remark}
	Data $f$ iniettiva, $f^{-1}$ è una funzione: $\Imm(f) \longrightarrow \Dom(f)$ iniettiva.
	In particolare se $f$ è bigettiva: $A \longrightarrow B$, allora $f^{-1}$ è bigettiva.
\end{remark}

\begin{definition}
	Data $f: A \longrightarrow B$ e $A' \subseteq A$:
	\[ f_{|A'} \Mydef \{(x,y) \in A' \times B | f(x) = y\}
		\]
	$f_{|A'}$ ``$f$ \vocab{ristretta} ad $A'$'' è una funzione: $A' \longrightarrow B$.
\end{definition}

\begin{definition}
	Date $g : A \longrightarrow B$ e $f : B \longrightarrow C$:
	\[ f \circ g \Mydef \{(x,z) \in A \times C | z = f(g(x))\}\footnote{O più formalmente $\exists y(y = g(x) \land z = f(y))$.}
		\]
	$f \circ g$, ``$f$ \vocab{composta} con $g$'', è una funzione: $A \longrightarrow C$.
\end{definition}

\begin{notation}
	Indichiamo con $\id_A$ la \vocab{funzione identità su $A$}:
	\[ \id_A \Mydef \{(x,y) \in A \times A | x = y\} \; (= \Delta_A)
		\]
\end{notation}

\begin{remark}
	Data $f : A \longrightarrow B$ bigettiva e $g : B \longrightarrow A$, sono equivalenti:
	\[ g = f^{-1} \qquad g \circ f = \id_A \qquad f \circ g = \id_B
		\]
\end{remark}

\begin{exercise}
	Data $g : A \longrightarrow B$ e $f: B \longrightarrow C$, sotto quali condizioni $f \circ g$ è iniettiva, suriettiva, bigettiva?
\end{exercise}

\begin{exercise}
	Data una relazione di equivalenza $\sim$ su $A$, dimostra che esiste un insieme $\faktor{A}{\sim}$ ed una funzione surgettiva $i_\sim$ da $A$ a $\faktor{A}{\sim}$
	tale che:
	\[ \forall x,y \in A \; x \sim y \leftrightarrow i_\sim(x) = i_\sim(y)
		\]
\end{exercise}

\begin{exercise}
	Data una relazione di equivalenza $\sim$ su $A$ e $f : A \longrightarrow B$, affinché esista $\widetilde{f}: \faktor{A}{\sim} \longrightarrow B$ tale che $f = \widetilde{f} \circ i_\sim$,
	è necessario e sufficiente che $\forall x,y \in A \; x \sim y \rightarrow f(x) = f(y)$.
\end{exercise}

\newpage
\section{Assioma dell'infinito e numeri naturali}
\subsection{Gli assiomi di Peano}
\newpage
\subsection{L'ordine di omega}
\newpage
\subsection{Induzione forte e principio del minimo}
\newpage
\subsection{Ricorsione numerabile}




\newpage
\section{Cardinalità}
\subsection{Teorema di Cantor-Berstein}
\newpage
\subsection{Teorema di Cantor}
\newpage
\subsection{Operazioni fra cardinalità}





\newpage
\section{Cardinalità finite}
\subsection{Principio dei cassetti}
\newpage
\subsection{Operazioni fra le cardinalità finite}




\newpage
\section{La cardinalità numerabile}
\subsection{Insiemi numerabili in pratica}
\newpage
\subsection{Prodotto di numerabili è numerabile}
\newpage
\subsection{Numeri interi e razionali}
\newpage
\subsection{Ordini densi numerabili}
\newpage
\subsection{Il grafo random}




\newpage
\section{I numeri reali e la cardinalità del continuo}
\subsection{Caratterizzazione dei reali come ordine}
\newpage
\subsection{La cardinalità del continuo è 2 alla alef-zero}
\newpage
\subsection{Operazioni che coinvolgono la cardinalità del continuo}
\newpage
\subsection{Sottrarre un numerabile dal continuo}




\newpage
\section{Stato del corso}




\newpage
\section{I buoni ordinamenti}
\subsection{Operazioni fra buoni ordinamenti}
\newpage
\subsection{Gli ordinali di Von Neumann}
\newpage
\subsection{Assioma del rimpiazzamento}
\newpage
\subsection{Induzione e ricorsione transfinita}
\newpage
\subsection{Operazioni fra gli ordinali}




\newpage
\section{Aritmetica ordinale e forma normale di Cantor}
\subsection{Sottrazione e divisione euclidea}
\newpage
\subsection{La forma normale di Cantor}
\newpage
\subsection{Punti fissi e epsilon-numbers}
\newpage
\subsection{Operazioni in forma normale di Cantor}
\newpage





\newpage
\section{Gli alef}
\subsection{Teorema di Hartogs}
\newpage
\subsection{Somme e prodotti di alef}



\newpage
\section{L'assioma della scelta}
\subsection{Buon ordinamento implica AC}
\newpage
\subsection{AC implica buon ordinamento (idea)}
\newpage
\subsection{Zorn implica buon ordinamento}
\newpage
\subsection{AC implica Zorn}
\newpage
\subsection{Conseguenze immediate di AC}
\newpage
\subsection{Esempi di applicazione di AC}
\newpage
\subsection{Basi di spazi vettoriali}
\newpage
\subsection{Invariante di Dehn}
\newpage
\subsection{Insieme di Vitali}
\newpage
\subsection{Teorema di Cantor-Bendixson}
\newpage
\subsection{Teorema di Tarski sulla scelta}









\newpage
\section{Aritmetica cardinale}
\subsection{Somme e prodotti infiniti}
\newpage
\subsection{Teorema di König}
\newpage
\subsection{Cofinalità}
\newpage
\subsection{Formula di Hausdorff}






\newpage
\section{Gerarchia di Von Neumann}
\subsection{Formule relativizzate ad una classe}
\newpage
\subsection{Assioma di buona fondazione}
\newpage
\subsection{Principio di epsilon-induzione}


\end{document}